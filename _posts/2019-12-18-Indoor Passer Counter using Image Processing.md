---
layout: post
comments: true
use_math: true
title: Indoor Passer Counter using Image Processing
categories: ["PROJECTS"]
---

**아직 작성중이라능!**   

# Contents
1. Description
2. Conceptual Design

------------------

# 1. Description
**수행기간: *2019. 09 ~ 2019. 12***   
   
<!-- 데모동영상 -->
{% include youtube.html id="Qzbkb-v91pE" %}{: .center}
   
*본 프로젝트는 실내의 일직선상의 통로에서 특정 방향으로 지나간 사람의 수를 세는 프로젝트로서, 본 프로그램이 임베드된 라즈베리파이와 카메라모듈을 건물 천장에 부착하여 사용하도록 고안되었다.*

## Stack
+ Raspberry Pi
+ OpenCV
+ C++ 

------------------


# 2. Conceptual Design

제약사항은 다음과 같았다.
+ 라즈베리파이 사용 및 엣지 컴퓨팅 (저전력, 저비용)

일반적으로 이미지에서 사람을 검출하는 데에는 Object Detection을 수행하는 머신러닝 솔루션을 적용하지만, 라즈베리파이라는 단일보드 하드웨어 특성상 머신러닝 등의 고연산을 요하는 작업을 실시간으로 수행하는 것은 불가능했다. 때문에 더욱 효율적인 방법을 찾기 위해 먼저 카메라가 촬영하는 영상의 특징을 분석하였고, 다음과 같은 특징들을 얻을 수 있었다. 아래 이미지는 실제 라즈베리파이 카메라를 천장에 부착하여 지나가는 사람을 촬영한 영상이다.   
   

![image]({{"/assets/images/2019-12-18-1.png"| relative_url}}){: width="75%" height="75%"}{: .center}   
   

1. 영상 내에서 사람의 이동은 일직선이다.
2. 영상 내에서 사람이 차지하는 크기는 어느 위치에 존재하더라도 대부분 일정하다.
   
위 두 가지 특징을 토대로, 다음과 같은 메인루프를 설계하였다.    
    
   
![image]({{"/assets/images/2019-12-18-2.png"| relative_url}}){: width="75%" height="75%"}{: .center}   
   
------------------
   
# 3. Implementation

## 3.1. Detecting

### 3.1.1. Why Background Subtraction?
차영상(Background subtraction) 기법이란, 이전 프레임과 현재 프레임간의 픽셀값 차이를 이용하여 일정 임계값 이상 변화를 보인 픽셀(Foreground)과 그렇지 않은 픽셀(Background)들을 이진으로 분류하는 기법이다. 이를 이용하면 CCTV와 같이 위치와 각도를 유지한 채 촬영하는 영상 속에서 물체의 움직임을 감지할 수 있다. 나는 이를 이용하여 사람을 검출하고자 하였다. 아래 이미지는 실내의 천장에 부착된 카메라로 바닥을 촬영하며 실시간으로 차영상 기법을 적용하는 예시이다. 좌측은 원본 프레임 및 지나가는 사람의 수를 세기 위한 부차적인 작업들을 나타낸 것이며, 우측은 원본 영상에 대해 차영상을 실시간으로 적용하여 배경(Background, 검정색)과 움직이는 물체(Foreground, 흰색)을 분리한 모습이다. 앞으로 이 흰 색의 덩어리를 "Blob" 이라고 지칭한다.   
   
![image]({{"/assets/images/2019-12-18-3.png"| relative_url}}){: width="100%" height="100%"}{: .center}   
   
차영상 기법은 OpenCV에 구현되어있는 MOG2 를 사용하였다.

### 3.1.2. Pure Blob
차영상 기법을 이용하여 움직임을 검출하려면, 내가 원하는 정도의 픽셀값 변화만이 Blob으로 깔끔하게 잡혀야만 했고, 이를 위해 빛 혹은 그림자에 의한 노이즈에 둔감한 차영상 모델을 만들어야 했다. 본 장은 이를 위해 수행한 내용들이다.       

1. MOG2의 파라미터 조정
API 적인 측면에서 내가 조정할 수 있는 파라미터는 이하의 두 가지가 존재했다. 각 파라미터를 결정하게 된 경위도 함께 기술하였다.   

+ ```history: int```   
*현재 프레임에서 움직이는 물체를 검출할 때, 최대 몇 프레임 이전의 것까지 활용할 것인지를 결정 (즉, 프레임 수)*   
![image]({{"/assets/images/2019-12-18-4.png"| relative_url}}){: width="100%" height="100%"}{: .center}   

위 이미지에서 볼 수 있듯 본 파라미터는 일정 값이 넘어가면 결과에 차이를 주지 않았다. 그리고 후술할 노이즈제거 및 후처리의 단계를 수행하기 때문에, 1로 설정하였다.


+ ```varThreshold: double```   
*어느 정도의 변화까지를 움직인 픽셀로 볼 것인지를 결정하는 임계값*   
![image]({{"/assets/images/2019-12-18-5.png"| relative_url}}){: width="100%" height="100%"}{: .center}   

본 파라미터는 카메라가 설치된 곳의 조명, 그림자여부 등에 따라서 결과가 극명하게 바뀌었고, 이때문에 카메라를 설치한 장소마다 (혹은 테스트영상마다) 이 파라미터를 새로 조정해줘야 하는 문제가 있었다. 이를 위해 "설치 단계"를 본 프로젝트의 전체 시나리오에 새로 추가했으며, 이 단계에서 경사 하강법을 이용하여 최적의 파라미터를 찾도록 구현했다.
![image]({{"/assets/images/2019-12-18-6.png"| relative_url}}){: width="100%" height="100%"}{: .center}   
위 이미지에서 사람을 감싸는 연두색 박스를 ROI(Rectangular region of Interest)라고 지칭하자.


2. 차영상 적용 후 노이즈제거를 위한 후처리
![image]({{"/assets/images/2019-12-18-00.png"| relative_url}}){: width="100%" height="100%"}{: .center}   

#### 문제 1. 사람이 아닌 물체, 혹은 빛에 의한 노이즈로부터 어떻게 사람을 구분할 것인가?
**Foreground로 추출된 Blob의 정보만을 통해 사람여부를 가리기 위해 Blob의 크기가 사람 한 명 정도의 크기인지를 따지기로 했다.** 이 때 다음 두 가지 문제를 고려해야 했다.

1. 영상 내에서 사람의 크기는 카메라가 설치된 높이에 따라 천차만별이므로 고정된 값으로 정의할 수 없다.
2. 노이즈가 크게 잡힐 경우 단순히 그 크기때문에 사람으로 오인할 수 있다.

위 두 문제점을 해결하기 위해 사람의 크기에 해당하는 ROI(사람이 검출되었을 경우 그 사람에게 할당되는 관심박스, 위 이미지에서 연두색 박스에 해당한다)를 카메라 설치 단계에서 설정하고, 이후 프레임에서 생성되는 Blob에 대해 ROI의 넓이 대비 Blob이 얼마나 많은 비율을 차지하는지를 기준으로 사람의 유무를 판별하였다.   
   

#### 문제 2. 설치장소 혹은 빛의 변화(태양광)에 따라 노이즈의 강도가 달라지는 건 어떻게 자동화 할 것인가?

## 3.2. Tracking & Counting

## 3.3. UML




+ 사람 감지하기: 이전 프레임과 현재 프레임간의 차이를 이용하는 차영상 기법 이용
+ 감지된 사람 추적하기: Mean Shift 알고리즘 이용
+ 지나간 사람 수 세기: 감지된 사람의 초기 위치와 이동방향을 토대로 사람 수를 계산